{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "018267ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8beecb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b1a758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../speech_emotion_reco/data/merged_dataset.csv')\n",
    "df['savee'] = df['path'].apply(lambda x: 1 if 'savee' in x else 0)\n",
    "df['crema'] = df['path'].apply(lambda x: 1 if 'crema' in x else 0)\n",
    "df['ravdess'] = df['path'].apply(lambda x: 1 if 'ravdess' in x else 0)\n",
    "df['tess'] = df['path'].apply(lambda x: 1 if 'tess' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8a1c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       1924\n",
       "sad         1923\n",
       "fear        1923\n",
       "disgust     1923\n",
       "angry       1923\n",
       "neutral     1895\n",
       "surprise     452\n",
       "unknown      200\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64ed160d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>savee</th>\n",
       "      <th>crema</th>\n",
       "      <th>ravdess</th>\n",
       "      <th>tess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>3520</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>1.821451</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>3521</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.187574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>3522</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.157234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>3523</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>1.719410</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3524</th>\n",
       "      <td>3524</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.153878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3715</th>\n",
       "      <td>3715</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.135329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>3716</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>1.759320</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>3717</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.007211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>3718</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>1.815147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>3719</td>\n",
       "      <td>female</td>\n",
       "      <td>unknown</td>\n",
       "      <td>../speech_emotion_reco/data/tess/YAF_pleasant_...</td>\n",
       "      <td>2.450068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  gender  emotion  \\\n",
       "3520        3520  female  unknown   \n",
       "3521        3521  female  unknown   \n",
       "3522        3522  female  unknown   \n",
       "3523        3523  female  unknown   \n",
       "3524        3524  female  unknown   \n",
       "...          ...     ...      ...   \n",
       "3715        3715  female  unknown   \n",
       "3716        3716  female  unknown   \n",
       "3717        3717  female  unknown   \n",
       "3718        3718  female  unknown   \n",
       "3719        3719  female  unknown   \n",
       "\n",
       "                                                   path  duration  savee  \\\n",
       "3520  ../speech_emotion_reco/data/tess/YAF_pleasant_...  1.821451      0   \n",
       "3521  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.187574      0   \n",
       "3522  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.157234      0   \n",
       "3523  ../speech_emotion_reco/data/tess/YAF_pleasant_...  1.719410      0   \n",
       "3524  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.153878      0   \n",
       "...                                                 ...       ...    ...   \n",
       "3715  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.135329      0   \n",
       "3716  ../speech_emotion_reco/data/tess/YAF_pleasant_...  1.759320      0   \n",
       "3717  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.007211      0   \n",
       "3718  ../speech_emotion_reco/data/tess/YAF_pleasant_...  1.815147      0   \n",
       "3719  ../speech_emotion_reco/data/tess/YAF_pleasant_...  2.450068      0   \n",
       "\n",
       "      crema  ravdess  tess  \n",
       "3520      0        0     1  \n",
       "3521      0        0     1  \n",
       "3522      0        0     1  \n",
       "3523      0        0     1  \n",
       "3524      0        0     1  \n",
       "...     ...      ...   ...  \n",
       "3715      0        0     1  \n",
       "3716      0        0     1  \n",
       "3717      0        0     1  \n",
       "3718      0        0     1  \n",
       "3719      0        0     1  \n",
       "\n",
       "[200 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['emotion']=='unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9821b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_path = '../speech_emotion_reco/data/images_v2/'\n",
    "    classes = {'happy': 0, \n",
    "               'sad': 1,\n",
    "               'fear': 2,\n",
    "               'disgust': 3,\n",
    "               'angry': 4,\n",
    "               'neutral': 5,\n",
    "               'surprise': 6,\n",
    "               'unknown': 7}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    images_path = [os.path.join(data_path, path) for path in os.listdir(data_path) if path.find('.png') > 0]\n",
    "    index = 0\n",
    "    for path in images_path:\n",
    "        if classes[df.loc[index, 'emotion']] in [0,1,2,3,4,5]:\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            resized_image = image.resize((256,256))\n",
    "            imgs.append(np.array(resized_image))\n",
    "            labels.append(classes[df.loc[index, 'emotion']])\n",
    "        index += 1\n",
    "        \n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c72f10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7d9d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11511, 256, 256, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6465e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11511, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afe45013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size= 0.16, test_size=0.04, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcf73475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1841, 256, 256, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "463e6ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(461, 256, 256, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ea98d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(120, kernel_size=11, activation=\"relu\", strides=4, input_shape=(256,256,3)))\n",
    "    model.add(layers.MaxPooling2D(3, strides=2))\n",
    "    model.add(layers.Conv2D(256, kernel_size=5, activation=\"relu\", strides=1))\n",
    "    model.add(layers.Conv2D(384, kernel_size=3, activation=\"relu\"))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(2048, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd4bd3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():  \n",
    "    model = load_model()\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74877a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 12:17:45.020493: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-28 12:17:45.021012: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 12:17:47.555721: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-08-28 12:17:47.562173: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-28 12:17:48.013335: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/92 [>.............................] - ETA: 12:08 - loss: 60.9013 - accuracy: 0.2625"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2, \n",
    "                    epochs=50, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4c1301f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Plugin\n",
      "Init Graph Optimizer\n",
      "Init Kernel\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
    "from tensorflow.keras import regularizers, Sequential, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5952387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../speech_emotion_reco/data/merged_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62c97c47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy       1924\n",
       "sad         1923\n",
       "fear        1923\n",
       "disgust     1923\n",
       "angry       1923\n",
       "neutral     1895\n",
       "surprise     452\n",
       "unknown      200\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f21fbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['savee'] = df['path'].apply(lambda x: 1 if 'savee' in x else 0)\n",
    "df['crema'] = df['path'].apply(lambda x: 1 if 'crema' in x else 0)\n",
    "df['ravdess'] = df['path'].apply(lambda x: 1 if 'ravdess' in x else 0)\n",
    "df['tess'] = df['path'].apply(lambda x: 1 if 'tess' in x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36fc82d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7443\n",
       "0    4720\n",
       "Name: crema, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.crema.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32b7f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "crema_df = df[df['crema'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f774fce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy      1272\n",
       "angry      1271\n",
       "disgust    1271\n",
       "sad        1271\n",
       "fear       1271\n",
       "neutral    1087\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_df.emotion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da110d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "      <th>savee</th>\n",
       "      <th>crema</th>\n",
       "      <th>ravdess</th>\n",
       "      <th>tess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4720</th>\n",
       "      <td>4720</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1022_ITS_ANG...</td>\n",
       "      <td>2.435782</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4721</th>\n",
       "      <td>4721</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1037_ITS_ANG...</td>\n",
       "      <td>3.003039</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4722</th>\n",
       "      <td>4722</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1060_ITS_NEU...</td>\n",
       "      <td>2.402404</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4723</th>\n",
       "      <td>4723</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1075_ITS_NEU...</td>\n",
       "      <td>2.435782</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4724</th>\n",
       "      <td>4724</td>\n",
       "      <td>female</td>\n",
       "      <td>disgust</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1073_IOM_DIS...</td>\n",
       "      <td>2.869569</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12158</th>\n",
       "      <td>12158</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1089_WSI_ANG...</td>\n",
       "      <td>2.268980</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12159</th>\n",
       "      <td>12159</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1025_IWW_ANG...</td>\n",
       "      <td>2.002041</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12160</th>\n",
       "      <td>12160</td>\n",
       "      <td>female</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1030_IWW_ANG...</td>\n",
       "      <td>2.369025</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12161</th>\n",
       "      <td>12161</td>\n",
       "      <td>male</td>\n",
       "      <td>angry</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1019_TIE_ANG...</td>\n",
       "      <td>3.303356</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12162</th>\n",
       "      <td>12162</td>\n",
       "      <td>female</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/crema/1079_IEO_NEU...</td>\n",
       "      <td>2.068753</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7443 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  gender  emotion  \\\n",
       "4720         4720    male    angry   \n",
       "4721         4721  female    angry   \n",
       "4722         4722  female  neutral   \n",
       "4723         4723  female  neutral   \n",
       "4724         4724  female  disgust   \n",
       "...           ...     ...      ...   \n",
       "12158       12158  female    angry   \n",
       "12159       12159  female    angry   \n",
       "12160       12160  female    angry   \n",
       "12161       12161    male    angry   \n",
       "12162       12162  female  neutral   \n",
       "\n",
       "                                                    path  duration  savee  \\\n",
       "4720   ../speech_emotion_reco/data/crema/1022_ITS_ANG...  2.435782      0   \n",
       "4721   ../speech_emotion_reco/data/crema/1037_ITS_ANG...  3.003039      0   \n",
       "4722   ../speech_emotion_reco/data/crema/1060_ITS_NEU...  2.402404      0   \n",
       "4723   ../speech_emotion_reco/data/crema/1075_ITS_NEU...  2.435782      0   \n",
       "4724   ../speech_emotion_reco/data/crema/1073_IOM_DIS...  2.869569      0   \n",
       "...                                                  ...       ...    ...   \n",
       "12158  ../speech_emotion_reco/data/crema/1089_WSI_ANG...  2.268980      0   \n",
       "12159  ../speech_emotion_reco/data/crema/1025_IWW_ANG...  2.002041      0   \n",
       "12160  ../speech_emotion_reco/data/crema/1030_IWW_ANG...  2.369025      0   \n",
       "12161  ../speech_emotion_reco/data/crema/1019_TIE_ANG...  3.303356      0   \n",
       "12162  ../speech_emotion_reco/data/crema/1079_IEO_NEU...  2.068753      0   \n",
       "\n",
       "       crema  ravdess  tess  \n",
       "4720       1        0     0  \n",
       "4721       1        0     0  \n",
       "4722       1        0     0  \n",
       "4723       1        0     0  \n",
       "4724       1        0     0  \n",
       "...      ...      ...   ...  \n",
       "12158      1        0     0  \n",
       "12159      1        0     0  \n",
       "12160      1        0     0  \n",
       "12161      1        0     0  \n",
       "12162      1        0     0  \n",
       "\n",
       "[7443 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crema_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c31d036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12163, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "395a3904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aea17079",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_indices = list(df[df['emotion'] == 'unknown'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c2e6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(reduction_factor=0.10):\n",
    "    unknown_indices = list(df[df['crema'] == 0].index)\n",
    "    unknown_path = [f'../speech_emotion_reco/data/images/{i}.png' for i in unknown_indices]\n",
    "    data_path = '../speech_emotion_reco/data/images/'\n",
    "    classes = {'happy': 0, \n",
    "               'sad': 1,\n",
    "               'fear': 2,\n",
    "               'disgust': 3,\n",
    "               'angry': 4,\n",
    "               'neutral': 5,\n",
    "               'surprise': 6,\n",
    "               'unknown': 7}\n",
    "    imgs = []\n",
    "    labels = []\n",
    "    images_path = [os.path.join(data_path, path) for path in os.listdir(data_path) if path.find('.png') > 0]\n",
    "    known_images_path = [path for path in images_path if path not in unknown_path]\n",
    "    index = 4720 \n",
    "    for path in known_images_path:\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        imgs.append(np.array(image))\n",
    "        labels.append(classes[df.loc[index, 'emotion']])\n",
    "        index += 1\n",
    "    print(set(labels))\n",
    "        \n",
    "    X = np.array(imgs)\n",
    "    num_classes = len(set(labels))\n",
    "    y = to_categorical(labels, num_classes)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "#random.sample(known_images_path, int(len(known_images_path)*reduction_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af45e740",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(reduction_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20748714",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b27e138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7443, 288, 432, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffaacb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7443, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7818e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = VGG16(weights=\"imagenet\", include_top=False, input_shape=X_train[0].shape)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8617d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:45:27.233872: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-25 11:45:27.242544: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-08-25 11:45:27.243939: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 288, 432, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 288, 432, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 288, 432, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 144, 216, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 144, 216, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 144, 216, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 72, 108, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 72, 108, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 72, 108, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 72, 108, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 36, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 36, 54, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 36, 54, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 36, 54, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 27, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 13, 512)        0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96e381b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 288, 432, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 288, 432, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 288, 432, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 144, 216, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 144, 216, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 144, 216, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 72, 108, 128)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 72, 108, 256)      295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 72, 108, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 72, 108, 256)      590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 36, 54, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 36, 54, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 36, 54, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 36, 54, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 18, 27, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 18, 27, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 9, 13, 512)        0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def set_nontrainable_layers(model):\n",
    "    # Set the first layers to be untrainable\n",
    "    model.trainable = False\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = set_nontrainable_layers(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b151a670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_layers(model):\n",
    "    '''Take a pre-trained model, set its parameters as non-trainables, and add additional trainable layers on top'''\n",
    "    base_model = set_nontrainable_layers(model)\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer = layers.Dense(500, activation='relu')\n",
    "    dropout_layer = layers.Dropout(0.2)\n",
    "    prediction_layer = layers.Dense(6, activation='softmax')\n",
    "    \n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer,\n",
    "        dropout_layer,\n",
    "        prediction_layer\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bc05d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 9, 13, 512)        14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 59904)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               29952500  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 3006      \n",
      "=================================================================\n",
      "Total params: 44,670,194\n",
      "Trainable params: 29,955,506\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = add_last_layers(model)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d892219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():  \n",
    "    model = load_model()\n",
    "    model = add_last_layers(model)\n",
    "    \n",
    "    opt = optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3241754",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9575f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train) \n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2aabd6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5954, 288, 432, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf2a88c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5954, 6)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c24cbe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:46:57.223855: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:46:57.998853: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - ETA: 0s - loss: 2.8798 - accuracy: 0.1709"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 11:51:50.145624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298/298 [==============================] - 370s 1s/step - loss: 2.8798 - accuracy: 0.1709 - val_loss: 1.7991 - val_accuracy: 0.1797\n",
      "Epoch 2/50\n",
      "298/298 [==============================] - 453s 2s/step - loss: 1.7940 - accuracy: 0.1862 - val_loss: 1.8036 - val_accuracy: 0.1646\n",
      "Epoch 3/50\n",
      "298/298 [==============================] - 458s 2s/step - loss: 1.7808 - accuracy: 0.2049 - val_loss: 1.8031 - val_accuracy: 0.1746\n",
      "Epoch 4/50\n",
      "298/298 [==============================] - 497s 2s/step - loss: 1.7670 - accuracy: 0.2076 - val_loss: 1.7997 - val_accuracy: 0.1755\n",
      "Epoch 5/50\n",
      "298/298 [==============================] - 569s 2s/step - loss: 1.7519 - accuracy: 0.2221 - val_loss: 1.8199 - val_accuracy: 0.1713\n",
      "Epoch 6/50\n",
      "298/298 [==============================] - 535s 2s/step - loss: 1.7079 - accuracy: 0.2482 - val_loss: 1.8630 - val_accuracy: 0.1788\n",
      "Epoch 7/50\n",
      "298/298 [==============================] - 551s 2s/step - loss: 1.6711 - accuracy: 0.2710 - val_loss: 1.8699 - val_accuracy: 0.1713\n",
      "Epoch 8/50\n",
      "298/298 [==============================] - 600s 2s/step - loss: 1.6215 - accuracy: 0.2904 - val_loss: 1.8848 - val_accuracy: 0.1587\n",
      "Epoch 9/50\n",
      "298/298 [==============================] - 607s 2s/step - loss: 1.5528 - accuracy: 0.3300 - val_loss: 1.8892 - val_accuracy: 0.1646\n",
      "Epoch 10/50\n",
      "298/298 [==============================] - 616s 2s/step - loss: 1.4936 - accuracy: 0.3609 - val_loss: 1.8935 - val_accuracy: 0.1629\n",
      "Epoch 11/50\n",
      "298/298 [==============================] - ETA: 0s - loss: 1.4188 - accuracy: 0.3953"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_split=0.2, \n",
    "                    epochs=50, \n",
    "                    batch_size=16, \n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045898b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_own_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=X_train[0].shape))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=6, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88abf6c8",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "model = load_own_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83ccc61",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = load_own_model()\n",
    "model = compile_model(model)\n",
    "\n",
    "es = EarlyStopping(patience=10, verbose=2)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                            validation_split=0.3,\n",
    "                            epochs=100, \n",
    "                            batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

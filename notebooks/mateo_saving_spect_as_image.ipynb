{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cb5c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8787ae2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_df = pd.read_csv(\"../speech_emotion_reco/data/merged_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30eb04ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gender</th>\n",
       "      <th>emotion</th>\n",
       "      <th>path</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>../speech_emotion_reco/data/savee/JK_sa01.wav</td>\n",
       "      <td>4.511837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>sad</td>\n",
       "      <td>../speech_emotion_reco/data/savee/JK_sa15.wav</td>\n",
       "      <td>6.058730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_n13.wav</td>\n",
       "      <td>2.788889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>surprise</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_su09.wav</td>\n",
       "      <td>3.433968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>male</td>\n",
       "      <td>neutral</td>\n",
       "      <td>../speech_emotion_reco/data/savee/DC_n07.wav</td>\n",
       "      <td>4.051791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 gender   emotion                                           path  \\\n",
       "0           0   male       sad  ../speech_emotion_reco/data/savee/JK_sa01.wav   \n",
       "1           1   male       sad  ../speech_emotion_reco/data/savee/JK_sa15.wav   \n",
       "2           2   male   neutral   ../speech_emotion_reco/data/savee/DC_n13.wav   \n",
       "3           3   male  surprise  ../speech_emotion_reco/data/savee/DC_su09.wav   \n",
       "4           4   male   neutral   ../speech_emotion_reco/data/savee/DC_n07.wav   \n",
       "\n",
       "   duration  \n",
       "0  4.511837  \n",
       "1  6.058730  \n",
       "2  2.788889  \n",
       "3  3.433968  \n",
       "4  4.051791  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89d23a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12163"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emotion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40338e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../speech_emotion_reco/data/savee/JK_sa01.wav'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_df.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c2eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=emotion_df.iloc[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "890ea256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../speech_emotion_reco/data/savee/JK_sa01.wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5896a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_image(path, image_id):\n",
    "    fig = plt.figure\n",
    "    samples, sample_rate = librosa.load(path, sr=44100)\n",
    "    sgram = librosa.stft(samples)\n",
    "    sgram_mag, _ = librosa.magphase(sgram)\n",
    "    mel_scale_sgram = librosa.feature.melspectrogram(S=sgram_mag, sr=sample_rate)\n",
    "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "    librosa.display.specshow(mel_sgram, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "    #plt.colorbar(format='%+2.0f dB')\n",
    "    filename = \"../speech_emotion_reco/data/images_v2/\"+image_id\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename,bbox_inches='tight',transparent=True, pad_inches=0)\n",
    "    plt.close()\n",
    "    del filename, samples, sample_rate,sgram, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043ed98",
   "metadata": {},
   "source": [
    "def saving_spect(path, image_id):\n",
    "    fig = plt.figure()\n",
    "    data, sample_rate = librosa.load(path, sr=44100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sgram = librosa.stft(samples)\n",
    "    librosa.display.specshow(sgram)\n",
    "    \n",
    "    sgram = librosa.stft(data)\n",
    "    mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "    librosa.display.specshow(mel_sgram, sr=sample_rate, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7152f34f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(8550,len(emotion_df)):\n",
    "    saving_image(emotion_df.iloc[i,3],str(emotion_df.iloc[i,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84c3c3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/raphaelvoortman/code/caronarthur/speech_emotion_reco/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc43e3de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
